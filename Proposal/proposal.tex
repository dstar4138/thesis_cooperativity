%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% PROJECT PROPOSAL  DESCRIPTION:
%   A concise description of the main concepts of the proposed project.
%
% RESEARCH:
%   A list of research activities which led to this project.
%
% EXPERIMENTS:
%   A list of the experiments performed which supported the research.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Define a single space environment (copied from doublespace.sty)
% e.g. \begin{singlespace}
%         single-spaced text
%      \end{singlespace}

\documentclass[11pt,american]{article}
\usepackage{fullpage}
\usepackage{bbm}
\usepackage{url}
\usepackage{subfigure}
\usepackage{color}
\usepackage{babel}
\usepackage{times}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{lscape}
\usepackage{verbatim}
\usepackage{fancyvrb}
\usepackage{enumerate}
\usepackage{afterpage}
\usepackage{setspace}
\usepackage{paralist} %% inline lists
\usepackage{tikz,tikz-qtree}

\graphicspath{ {./pics/} }
\begin{document}
\thispagestyle{empty} 
\begin{center}
{\em MS Thesis Proposal}\\
\vspace{.5in}
{\huge \bf Process Cooperativity as a Feedback Metric \\
            in Concurrent Message-Passing Languages }\\
\vspace{.5in}
{\bf Alexander Robert Dean}\\
{\footnotesize \url{ard4138@cs.rit.edu}}\\
\vfill
\
{\em Committee Chair:} Dr. Matthew Fluet Ph.D.\\
\vspace{0.05in}
{\em Reader: } Dr. James Heliotis Ph.D.\\
 \vspace{0.15in}
Department of Computer Science\\
B. Thomas Golisano College of Computing and Information Sciences \\
Rochester Institute of Technology \\
Rochester, New York \\ [0.3in]
\vspace{0.5in}
\today{}\\
\end{center}
\vfill

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  Collection of useful abbreviations.
\newcommand{\etc} {\emph{etc.\/}}
\newcommand{\etal}{\emph{et~al.\/}}
\newcommand{\eg}  {\emph{e.g.\/}}
\newcommand{\ie}  {\emph{i.e.\/}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Abstract
\section*{Abstract}
Runtime systems for concurrent languages have begun to utilize feedback mechanisms to influence their
scheduling behavior as the application proceeds. These feedback mechanisms rely on metrics by which to
grade any alterations made to the scheduling system. As the application's phase shifts, the feedback mechanism
is tasked with modifying the scheduler to reduce it's overhead and increase the application's efficiency.

Cooperativity is another possible metric by which to grade a system. In biochemistry the term cooperativity
is defined as the increase or decrease in the rate of interaction between a reactant and a protein as
the reactant concentration increases. This definition translates well as an information theoretic definition
as: the increase or decrease in the rate of interaction between a process and a communication mode as the
number of processes increase. 

This work proposes a unique feedback mechanism and scheduling algorithm which takes advantage of this behavior.
It further compares this algorithm to other feedback metrics via a custom extensible runtime system developed to
support swappable scheduling mechanisms.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vfill{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is where the main body of the capstone proposal starts
\setcounter{page}{0} 
\newpage{}

\section{Background} % and Introduction
%% TOPICS:
%% - Description of Cybernetics, feedback systems?
%% - Runtime systems
%%	 - Concurrent (not necessarily parallel)
%%	 - Feedback metrics (related work?)
%%	 - How should Control theory be adapted for RTS? 
%%		 - Should be tight oscillations or constant so as to achieve minimal overhead from modification, we 
%%				don't care about issues of resonance.
%%		 - Can also disregard dampened movement as we do not have to worry about physical machinery, if we 
%%				can jump to the reference signal then we should.
%% - Message Passing Languages
%%	 - How it's different from calls, shared memory, pipes, ...
%%	 - Why limited to MPLs?
%%	 - Note there is a difference between Sync and Async.
%% - Related Work?
%%	 - Job Scheduling on distributed systems (typically long-run without the ability to interrupt)
%%	 - OS Process Scheduling (typically priority based and without much inter-process communication focus)
%%	 - 

Since the formalization of feedback driven systems and the advent of Cybernetics, multiple fields have attempted 
to mold these principles to their own models; and run-time schedulers are no exception. This is due, in part, from
process scheduling in parallel systems being fundamentally a NP-Complete problem \cite{bruno1976computer}. Instead,
focus has been more fruitful when pursuing the optimization of various metrics using some particular objective 
function \cite{garey1978performance} to tune for particular edge cases. As such, scheduling based on feedback 
metrics is not new \cite{dietz1997use}.

There is a big distinction though, which can be made between the effects of control theory in classical cybernetic applications 
versus that of run-time systems. This is primarily in the adaptation of the controller in the generic feedback 
loop (figure~\ref{fig:controller}).
In typical mechanical feedback loops there are two scenarios which need to be avoided: resonance 
and extreme compensation. It can be seen that most controller models will attempt to damp the adjustments to reduce 
oscillation which could cause resonance or sharp spikes in behavior based on its output. This is due to the  
limitations of the physical space in which they are having to deal with. 

However, in run-time scheduling systems we would very much like to do the opposite. We would prefer tight oscillations or 
consistent behavior of our runtime so as to achieve minimal overhead from our modifications. We can also compensate, 
to reach our reference signal, as quickly as we need to as there are no physical restrictions for our modifications. 
But this is only to note that we need to take an opposite approach to our scheduler implementations than classical 
theory.

\begin{figure}[htp]
\centering
\includegraphics[scale=0.55]{\detokenize{Feedback_loop_with_descriptions.jpg}} %detoken because of '_' char.
\caption{A classical feedback loop representation.}
\label{fig:controller}
\end{figure}

Run-time systems tend to extend to more than just the process-scheduling systems though. They also encompass  
garbage collection, dynamic type checking, statistical collection and other debugging mechanisms, and general 
resource allocation (\eg~I/O). For the purposes of this paper we will be exclusively talking about the process
scheduling system and intentionally ignore the effects of these other, albeit important, sub-systems. This 
distinction must be made however, as some scheduling systems also take into account the effects of these other
systems on the placement and order of process evaluation. For example, White \etal~\cite{white2012automated}
discuss heap size as a metric for process selection as a means of curtailing garbage collection times.

\subsection{Classical Run-Time Scheduling}

Another distinction must be made as far as the level of foresight the scheduling systems, within this paper, have.
There is a spectrum of clairvoyance in classical job-scheduling, in that on one end job-schedulers have full foresight
over the jobs which will enter the queue and their order. These schedulers have the opportunity to optimize for future
events, which is a luxury the scheduling systems, in this paper, do not have. 

However, as it is a spectrum, there is a single educated guess this subrange of schedulers can make. Namely, the first 
job will always be the last, and all other jobs will spawn from it. Thus there will always be a single process in the 
queue at the beginning. This is true as the runtime will always require an initial primary process (\eg~the `main' 
function), and once that function is completed, the system is terminated (despite the cases of unjoined children). 
Apart from this all other insights will need to be gleaned from the evaluation of this initial process.


\subsection{Message Passing}

In concurrent systems, there are a number of methods for inter-process communication. Arguably though, one 
of the more popular abstractions is the idea of message passing. Message passing in general can be broken down into 
two types, asynchronous or synchronous, and then further by how they are implemented. However, when discussing process
scheduling the method of their implementation is often of some consequence.

\begin{figure}[htp]
\centering
\Tree [ .{Message Passing}
			[ .Async 
				Direct 
				Indirect 
			] 
			[ .Sync 
				Asymmetric
				Symmetric 
			]
	   ]
\caption{A High-Level Message-Passing Taxonomy}
\label{fig:mptax}
\end{figure}

In asynchronous message passing a process can either be provided a rendezvous point or a identifier for another process.
To send a message in either case requires pushing/copying the message into a shared or global memory space for another
process to access (possibly) at a later time. This push/copy can be done in a lock free manner with some lower level
atomic data structures such as a double-ended queue. But in either a locked or lock-free manner, the process performing
the send still blocks (if only for a moment) on the operation. However, one difference to note is that the rendezvous 
point allows for the potential of many processes of accessing the message buffer at once.

In terms of scheduling, a language with asynchronous message passing can ignore the effects of blocking operations, but
will need to look closer at process placement to take advantage of possible gains in cache affinity \cite{debattista2002cache}.
For example, the effects of the cache on direct message passing (\eg~a process mailbox) can be substantial as two processes
on different cores will need to copy stack frames to memory and back rather than just a pointer to the message in the 
originator's stack frame. In indirect message passing the task is even worse as multiple processes may need access to the
same data.

In synchronous message passing, a process must meet another at a provided rendezvous point but can either be symmetrical
or asymmetrical. Note that the rendezvous point is not a requirement in the sense that direct synchronous messaging isn't 
possible. Instead we think of a rendezvous point in synchronous communication time bound rather than location bound (\ie~two
processes are blocked until communication occurs, the implementation of this passing is irrelevant to this 
classification).

However there is a further classification of synchronous message passing, that of symmetrical vs asymmetrical message passing. 
Asymmetrical message passing is synonymous with Milner's Calculus of Communicating Systems \cite{milner1982calculus} 
or the standard $\pi$-Calculus \cite{palamidessi1997comparing}, in that you have a sender and a receiver which will 
block on their respective functions around an anonymous channel until the pass has been completed. This differs from a 
symmetrical message passing only in that the only operation on the channel is a blocking swap-values with the
process on the other end. Note, it has been shown possible to implement symmetrical message passing on asymmetrical
message channels \cite{}.%TODO: FIND A CITATION FOR ASYMMETRICAL PROOF: Show CML swap channel??

In terms of scheduling of synchronizing processes, order is now a factor that needs to be considered. On top of this 
directionality can also be a factor which complicates the channel implementation. Namely, the internal queuing of senders or
receivers may not percolate hints up to the scheduler regarding their queue position. For the alternative, symmetrical message
passing or swap channels, the order is directly handled by the scheduling of the system (\ie the order at which the channels 
evaluate the $swap$ command can be directly governed).

%%%%%%TODO: MAKE THIS BETTER... IT NEEDS TO BE SAID AS IT LEADS TO MOTIVATION, BUT NO MOTIVATION IN THIS SECTION JUST BACKGROUND
%However, there is a distinction which must be made between uni- and bi-directional channels in terms of process
%operation. Or is it???? Part of the desired research is a study of channels with  uni- and bi-directionality. It is 
%obvious that middle-man can facilitate the
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Cooperativity as a Metric}


%However, this differs from capturing the cooperativity in that, while communication efficiency is important, 
% it misses the quantity of communication which could indicate needed changes in scheduling quantum.





\section{Motivation}
%%TODO:
%% - No Process Cooperativity metric has adequately been accounted for.
%%		- At least from the literature review I've done. However, their definitions might differ from our own.
%% - Metric calculation and scheduler comparisons have yet to have a good framework implementation for doing so.
%%


It has become a matter of analysis and experimentation to discover which metrics are of value, and to which criterion.
There has been work on metrics such as heap size \cite{white2012automated}, process locality 
\cite{debattista2002cache,ritson2012multicore}, and interactivity \cite{reppy1993concurrent} to name a few.

The motivation is twofold. Current feedback scheduling implementations fail to take process-cooperativity
into account when applying feedback. A scheduler implementation and metric calculation would aid in future
feedback schedulers. However, this hints at other missing metrics that could be useful for adapting to
application phases. A closer evaluation of current scheduling techniques on common language primitives
will allow for a constructive comparative analysis. This, as far as I'm aware, has not been done at the 
injected runtime level but rather only at the OS or Application levels with job schedulers.

Thus there would be a desire 

\section{Proposed Work} % Solution Design and Implementation
%%TODO:
%%	- Compiler Implementation:
%% 		- Design of the Language Specification (Simplistic language with small message passing constructs)
%%		- Design of Compiler?
%%			- Why Erlang?
%%			- How channels work?
%% 				- Examine fairness of communication mode and process selection.
%%			- Scheduling Interface (Plugin API)
%%	- Evaluation Techniques
%%		- How will I compare multiple schedulers?
%%		- What example applications?
%%		- Should I abstractly prove bounds of the scheduler? See paper
%%	- Cooperativity Algorithm
%%		- Explain what the metric means for a runtime.
%%			=> How does this differ from interactivity? 
%%				-> Interactivity is the ratio of communication to computation (i.e. an interactive system is one with high comm, low comp)
%%				-> Cooperativity is a per process measurement of ITS interactivity over time (i.e. a cooperative system is one with highly interactive
%%%						 processes, whereas a non-cooperative system is one with primarily cpu bound processes).
%%		- "What would an optimal Cooperativity ratio be?" is the wrong question, more like "How to improve process placement based on a timesteps' cooperativity measurement?"
%%			=> Application phase has a direct correspondence with the ratio of cooperativity desired. (I.E. early in the lifetime cooperativity may 
%%					be high to communicate initial goals, and this should be supported. However, as time moves forward cooperativity may decrease as
%%				    processes handle their individual tasks. That being said the opposite could be true, in that to fullfill their tasks they required
%%					help from neighbor processes.)
%%
%%



I have already begun to work on a compiler built with swappable scheduler's in mind. The language
is a simple lambda and process calculi with synchronous swap channels so as to minimize the language
characteristics which may mask the process-based metrics, such as differentiating between CPU, I/O,
and Channel bound processes. This compiler will also allow me to directly test multiple metrics and
scheduling techniques and visualize the system phases at any given point. I will attempt to do a
comparative analysis of several popular scheduling techniques against a new algorithm I will need to design
which uses cooperativity. This, in turn, will evaluate the effectiveness of the process and communication
channel abstractions utilized in the language.

\subsection{The ErLam Language}

\begin{figure} %% THE ERLAM LANGUAGE BNF WITHOUT SYNTAX SUGAR %%
\centering
\begin{BVerbatim}[commandchars=\\\{\}]
<Expression> ::= <Variable> 
              |  <Integer>
              |  `\textbf{newchan}'
              |  `\textbf{(}' <Expression> `\textbf{)}'
              |  <Expression> <Expression>
              |  `\textbf{if}' <Expression> <Expression> <Expression>
              |  `\textbf{swap}' <Channel> <Expression>
              |  `\textbf{spawn}' <Expression>
              |  `\textbf{fun}' <Variable> `\textbf{.}' <Expression>
\end{BVerbatim}
\caption{The ErLam language grammar, without syntax sugar or types.}
\label{fig:grammer}
\end{figure}

To compare multiple scheduling systems, we would require a language with minimal overhead but which would easily 
mimic common process behaviors. That being said, there are three primary qualities of a process which we would like to extract during its evaluation:
\begin{inparaenum}[\itshape a\upshape)]
\item the likelihood of communication from this process;
\item whether the process has children; and
\item whether two processes have a chance of communicating.
\end{inparaenum} 
The


\subsection{Expected Outcomes and Deliverables}

The end goal will be to have, at minimum, the scheduling algorithm based on process cooperativity and 
the ErLam compilation framework for testing it along-side other algorithms, completely implemented. The 
framework will have two parts: A new tool for comparative analysis of the inner workings of concurrent 
schedulers, and a set of high level language abstractions for future run-time scheduler testing.

Thus, there are two deliverables expected alongside the Thesis Report; the source code for a new compiler 
and runtime framework, and the implementation and design description of a new scheduling algorithm. Both
of which will be made available for public use after completion.

\section{Roadmap}

Based on the layout of the $10$-week Summer session of $2138$, where the tenth week
is the defense. It will primarily be a top-heavy load that will shift as needed
with the inevitability of roadblocks:\\

    April\\
        $4/28$ - Submission of Proposal with road-map.\\

    May\\
        $5/25$ - $5/31$ - Finish base ErLam Compiler and Plug-in Scheduler Interface \\

    June \\
        $6/01$ - $6/07$ - Port CML's interactivity scheduler to Erlang$^*$\\
        $6/08$ - $6/14$ - Cooperativity based Algorithm Development/Implementation \\
        $6/15$ - $6/21$ \\
        $6/22$ - $6/28$ - Implement Test Cases for Scheduler Comparisons\\

    July\\
        $6/29$ - $7/05$ - Draft of Thesis report submission {\em (hand off to Readers$^{**}$)} \\
        $7/06$ - $7/12$ - Run tests and compile results {\em (update Thesis)} \\
        $7/13$ - $7/19$ - {\em(Schedule Defense)}\\
        $7/20$ - $7/26$ \\

    August\\
        $7/27$ - $8/02$ - Primary Thesis Defense dates\\
        $8/03$ - $8/09$ - {\em(Backup Defense dates)}

\begin{itemize}
\item[$*$]{\small\em Stretch goal to implement a batching Occam-Pi scheduler also.}
\item[$**$]{\small\em The goal is to get the thesis to the readers as far ahead of time as possible, this week is buffer.}\\
\end{itemize}

Every week will contain at least one meeting with my chair and every two weeks
must result in an update to my website to lay out my progress and future work. 
I intend to update my Thesis report as the session progresses, my Chair will be 
able to view the progress through a shared version controlled repository. The
Readers will get two weeks with the draft (without finalized results) to make
suggestions before accepting a defense date. I will have three weeks concurrent
to this time for testing and report generation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak{}
\bibliographystyle{plain}
% Single space the bibliography to save space.
\singlespacing
\bibliography{proposal}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}
