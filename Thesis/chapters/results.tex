\chapter{Results and Discussion}
\index{Results and Discussion@\emph{Results and Discussion}}%
\label{chap:results}

\section{Evaluation}\label{sec:results-evaluation}

We begin our discussion by first stepping back and performing a meta-validation 
of the ErLam toolkit itself, before comparing the scheduling mechanisms amongst 
themselves. We ask:
\vspace{-3mm}\begin{itemize}
    \item How complex must our implementations be to create our test primitives? 
    \item For each scheduler, does our implementation work as expected, despite a minimalistic scheduler API?
    \item Does the channel implementation lend itself to scheduling improvements? If so, in what case?
\end{itemize}\vspace{-3mm}
These questions will evaluate ErLam, both as a language and runtime, but also as a 
simulator for scheduler experimentation, comparison, and evaluation. We attend to
these questions in order;
Section~\ref{sec:results-test-case-implementation} critiques the language as a 
medium for simulation design through the development of our test primitives.
Section~\ref{sec:results-evaluation-classical} discusses our evaluation of the
scheduler API using several of the testing primitives on the aforementioned 
classical schedulers. 
Then in section~\ref{sec:results-channel-implementations}, we discuss our findings 
regarding channel implementation differences and their subsequent effects on 
scheduling behavior.

\subsection{Test Case Implementation}\label{sec:results-test-case-implementation}

Our intentions when choosing our base language constructs were primarily focused on 
simplifying the base language. This minimalism we hoped would remove any noise 
which may be caused by the implementation details. We hoped to make, for lack of a better
term, a concurrent functional assembly language. As such, there was some concern
as to the level of ease we would be able to implement our testing primitives.

We start with a critique of the first implemented test case: $ChugMachine_N$. It
soon became apparent that we would need to standardize on a successive spawning
method for producing several of the same process at once. Rather than modifying
our $spawn$ expression we decided to implement this as a fuction in the language
as it was. The reasoning behind this was to keep consistent the effects of 
spawning a process into a process queue. If we allowed the process to produce $N$
processes at once, the lag caused by the runtime to produce them would be 
more noticable.

\begin{figure}
    \centering
{\footnotesize
\begin{BVerbatim}[commandchars=\\\{\}]
merge = \textbf{fun} a.(\textbf{let} x = \textbf{newchan} \textbf{in}
               \textbf{let} _ = (\textbf{spawn} \textbf{fun} _.(\textbf{swap} x (a nil))) \textbf{in}
               \textbf{fun} b.(\textbf{let} y = \textbf{newchan} \textbf{in} 
                      \textbf{let} _ = (\textbf{spawn} \textbf{fun} _.(\textbf{spawn} y (b nil))) \textbf{in}
                      \textbf{fun} m.(m (\textbf{swap} x nil) (\textbf{swap} y nil))))
// ...
(omega \textbf{fun} f,n.(\textbf{if} (leq n \textit{1}) 
                   (worker_t nil) 
                   (merge \textbf{fun} _.(f f (dec n)) worker_t ignore)) 
             N)
\end{BVerbatim}
}
    \caption{Our implementation for a map-reduce style fork-branch, and it's 
    subsequent standardized usage.}
    \label{fig:merge-code}
\end{figure}

We settled on the $merge$ function (figure~\ref{fig:merge-code}), along with a 
standard method of invoking it. Our $omega$ function would enable recursion, 
for us to use one branch of the $merge$ call to create a left-loaded binary
tree. This would keep a consistent behavior despite a bias towards the initial 
processes. Note that a work-stealing or global-queue scheduler would gain
access to the most recent processes sooner (and would thusly get a chance to
reduce sooner). 

Also as a side effect of our decision, there is a channel for every process which
immediately blocks. This has the added effect of giving us the ability to track when 
processes terminate, as the long-term blocked channels will start closing. For
example, figure~\ref{fig:fibonacci-channel-demo}, gives an example parallel
Fibonacci program written in this style and it's subsequent channel graph. This
is reminiscent of a map-reduce style approach, and the language lends itself
to it. Note on the channel graph, a dark line indicates a channel which 
becomes blocked until the point at which it becomes unblocked. 

\begin{SaveVerbatim}[commandchars=\\\{\}]{FibCode}
(omega \textbf{fun} f,m.(
    \textbf{if} (leq m 1) 
       m
       (merge \textbf{fun} _.(f f (sub m 1))
              \textbf{fun} _.(f f (sub m 2))
              add)) \textit{8})
\end{SaveVerbatim}
\begin{figure}[h!]

\subfigure{
    \includegraphics[scale=0.40]{fibonacci-channel-demo.pdf}
    \label{fig:fibonacci-channel-demo-chart}
}%
\subfigure{
    \centering
    \raisebox{20mm}{\footnotesize \BUseVerbatim{FibCode} }
\label{fig:fibonacci-channel-demo-code}
}
    \caption{Parallel Fibonacci implementation and a potential channel graph.}
    \label{fig:fibonacci-channel-demo}
\end{figure}

You may also note that the chart gives an indication as to the size of the time
quantum selected for the application's execution. The order in which a channel
becomes blocked, and it's order in the processes execution give that hint. The
large block of channels at the top of the graph indicate the last batch of 
spawned processes got time on the cpu before the one's which spawned it, as the
scheduler which evaluated the spawn ran out of reductions for that process. 
These observations will become useful for later scheduler critiques.

\subsection{Scheduler API}\label{sec:results-evaluation-classical}

The ErLam Scheduler API was minimally constructed around the single-step 
scheduling semantics presented earlier in figure~\ref{fig:scheduler-step}.
We were motivated by the simplicity of the description and thus the ability
to bring some formalism to the implementations. That being said, we would still
require the option to observe practical statistics such as runtime overhead 
during our scheduler comparisons. 

\begin{figure}[h!]
    \subfigure[Tick disparity, or the average time between scheduler ticks per 
    LPU, per Task run. Typical ranges tend to spike in groups, which show 
    consistency based on scheduler implementation, rather than OS intervention.]{
        \includegraphics[width=\textwidth]{tick-disparity.png}
        \label{fig:tick-disparity}
    }
    \subfigure[Tick disparity consistently matches up with increased computation, 
    which is indicitive of inter-scheduler communication requirements.]{
        \includegraphics[width=\textwidth]{tick-disparity-to-reductions.png}
        \label{fig:tick-disparity-match}
    }
    \caption{Tick Disparity over nearly $900$ tests.}
\end{figure}

However,
wne of the concerns early on, and as described in section~\ref{sec:runtime log reports}, 
was that the LPUs could greatly differ in the number of ticks they are able to 
provide their process queue. This could be caused by the OS preempting the 
ErLam scheduling thread to execute something else. However, from our tests, we
found these gaps to be minimal and mainly caused by the scheduling implementation
itself. 

Figure~\ref{fig:tick-disparity} shows the average time between ticks averaged over
the LPUs for a large subsection of the tests we ran. We call this average time 
between ticks per LPU the Tick Disparity of the test. From the figure, we notice
obvious clustering, and figure~\ref{fig:tick-disparity-match} leads us to believe this
is primarily caused by spikes in reduction counts. A scheduler chugging on 
processes the entire time, must wait until preemption in-order to handle any 
inter-scheduler communication, as in the case of work-stealing schedulers. Thus,
for our purposes, all talk of tick-disparity could be considered a discussion of
scheduler overhead. As such, comparative analysis of scheduler implementation 
overhead from test case execution would still be a valid comparison with our
design.

Further, to validate that our scheduler implementations functioned as expected 
after translation was another concern. We gave the example of the CML 
Dual-Queue translation ($STDQ$) previously in section~\ref{sec:example the cml scheduler}.
We will now examine it's execution and compare it to $STRR$, a single queue naive
scheduler to confirm our understanding.

The key differences we would expect to see in a comparison would be that the CML
prefers to, and attempts to run the interactive processes first. It would push
all computational processes onto the secondary queue, only promoting them when 
the need arises. To observe this property, we compose the $UserInput_{(T,C)}$ 
test with $ChugMachine_N$ to create an interactivity test primitive 
$Interactivity_{(N,M)}$ (figure~\ref{fig:interactivity-code}). The primitive
launches $ChugMachine_N$ and $M$ instances of $UserInput_{(5,10)}$ (the values
of which were arbitrarily chosen so as to execute for long enough to collect
coherent data). We then subsequently ran this primitive with $STRR$ and $STDQ$
using multiple values for $N$ and $M$. Table~\ref{tab:interativity8-16-strr-stdq}
compares an instance of this test set: $Interactivity_{(8,16)}$.

\begin{table}[!p]
    \begin{tabular}{@{}ccc}
$Interactivity_{(8,16)}$ & \textbf{$STRR$}       & \textbf{$STDQ$}       \\ \cline{2-3} 
\multicolumn{1}{c|}{\rotatebox{90}{\textbf{Channel State over Time}}} & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.32]{tests/interactivity/single/pg_0001.pdf}} & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.32]{tests/interactivity/cml/pg_0001.pdf}} \\ \cline{2-3} 
    \multicolumn{1}{@{}c|}{\rotatebox{90}{\textbf{Communication Density}}}   & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.32]{tests/interactivity/single/pg_0002.pdf}} & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.32]{tests/interactivity/cml/pg_0002.pdf}} \\ \cline{2-3} 
\multicolumn{1}{c|}{\rotatebox{90}{\textbf{Reduction Density}}}       & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.32]{tests/interactivity/single/pg_0003.pdf}} & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.32]{tests/interactivity/cml/pg_0004.pdf}} \\ \cline{2-3} 
\end{tabular}
    \caption{Comparison of $STRR$ and $STDQ$ using Channel State, Reduction and Communication Densities.}
    \label{tab:interativity8-16-strr-stdq}
\end{table}

The Reduction Density graphs explain everything we need to know. The darkened portions
at the beginning of the chart indicate that the $STRR$ scheduler has no regard for the
interactive processes, whereas the $STDQ$ scheduler remains spread out. This seems to be
on the opposite if we were to consult the Communication Density charts though. It would appear
here that $STRR$ is getting more frequent communication, and $STDQ$ condenses all 
synchronizations to the end. This is however an issue of verbiage as Interactivity
does not correlate to Communication Density. By this we mean, $STRR$ is indeed allowing 
communication to happen evenly due to a round-robin schedule, but it is not attending to
spontanious events (\ie~responses back from $hang$). $STDQ$ on the otherhand pushes all 
inter-process communication backwards as it waits to respond to the $hang$ing processes.

We see this effect more clearly once we compare with the Channel State charts. In $STRR$
we see an even regard for all processes. The tapering of the channel blocks at the 
beginning of the graph is consistent with our understanding of the $merge$-based
successive spawning. However, $STDQ$ is completely different, and all $UserInput_{(T,C)}$
processes seem to be pushed to the beginning of the execution pool. This is infact due
to another difference between the execution styles of the two schedulers. $STDQ$ replaces
the currently running process with the child process it spawned, enqueuing the parent.
We therefore can confirm our understanding, in this case, that the scheduler is reacting
to the test primitives as expected.

The work-stealing mechanic is another instance for interesting comparison. We've built
two of the cooperativity-conscious schedulers we discuss on top of the $MTRRWS$-$*$ 
process queue implementation. It is this unified queue implementation which allows 
us to toggle between the two implementations. With $MTRRWS$-$SQ$, the process queue
will respond to function calls from schedulers for other LPUs, it will perform a
quick dequeue from the bottom only blocking the host LPU from accessing the queue
for a minimal amount of time. With $MTRRWS$-$IS$, the process queue goes untouched
by other LPUs, instead the scheduler on the LPU itself will receive the messages
and respond during periods inbetween process operations.

To compare these, we would expect to see minor differences in the processes scheduler 
state as we could expect $MTRRWS$-$IS$ to wait longer for responses from their theif
messages. But otherwise we would like to make sure the saturation of the cores are 
as identical as possible. In other words, if either method is unable to saturate the 
cores effectually, then it would not be worth further testing (or there is an issue 
with the implementation). 

However, work-stealing schedulers work best if there is a constant probability of 
loosing a process by completion. Our test primitives, as they stand, do not account for
application phases in terms of process quantity. Thus, to effectively examine these
stealing mechanisms, we substitute process loss via completion with process loss via 
channel absorption. Thus, table~\ref{tab:ptree9-10-5-wsis-wssq} gives a comparison of the 
two work-stealing techniques in terms of scheduler state over time and the process 
queue length with a run of $PTree_{(9,10)}$ with channel absorption turned on.

\begin{table}[!p]
    \begin{tabular}{@{}ccc}
$PTree_{(9,10)}$ & \textbf{$MTRRWS$-$IS$}       & \textbf{$MTRRWS$-$SQ$}       \\ \cline{2-3} 
\multicolumn{1}{c|}{\rotatebox{90}{\textbf{Scheduler State}}} & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.32]{tests/ptree/wsis/pg_0005.pdf}} & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.32]{tests/ptree/wssq/pg_0005.pdf}} \\ \cline{2-3} 
\multicolumn{1}{c|}{\rotatebox{90}{\textbf{Process Queue Length}}}   & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.32]{tests/ptree/wsis/pg_0003.pdf}} & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.32]{tests/ptree/wssq/pg_0003.pdf}} \\ \cline{2-3} 
\end{tabular}
    \caption{Comparison of $MTRRWS$-$IS$ and $MTRRWS$-$SQ$ using Scheduler State and Queue Size.}
    \label{tab:ptree9-10-5-wsis-wssq}
\end{table}


Upon review of this comparison, our initial assumptions are validated. The process queue
length looks extremely similar. The LPU which owns the initial process maintains the 
largest queue, where all others work steal a single process and work on it. Any gains in
queue size for these LPUs are via channel absorption, but this can not compare with the
initial spawns. We note here that an obvious introduction of smarter work-balancing
would be critical for a realistic or even practically useful scheduler. However, for our
purposes of verifying the work-stealing mechanism, this is sufficient.

Although the scheduler state comparison, in this instance, does not look consistent with 
the original assumptions. Namely, $MTRRWS$-$IS$ seems not stay in waiting mode as long
as $MTRRWS$-$SQ$ does. However, we can pose two possible reasons for this reaction:
there is an obvious scaling bias introduced by squeezing over $11000$ ticks into the same length
of space as $MTRRWS$-$SQ$ does with $8000$. Additionally, the scheduling reduction quantum for 
this execution was $20$ and all processes were set to chug for only $5$ max, this allows the 
scheduler more opportunity to tend to inter-process communication at a detriment to
the shared-queue implementation due to higher chance of blocked queue access.
The simulation's log was able to support the former rational.

\subsection{Channel Implementations}\label{sec:results-channel-implementations}

The above graphs (\eg~table~\ref{tab:interativity8-16-strr-stdq}, and 
table~\ref{tab:ptree9-10-5-wsis-wssq}) were generated, using the CML-like Process 
Absorption channels. We would like to now breifly visualize how a Blocking channel
may operate and effect our visualization of the application's scheduling. In this example 
(table~\ref{tab:interactivity16-8-sq}), we ran the interactivity composure again
to test a large sampling of processes, but some with communication so as to see the 
flow of processes due to absorption.

\begin{table}[!p]
    \begin{tabular}{@{}ccc}
     \multicolumn{3}{c}{$Interactivity_{(16,8)}$ } \\ \cline{2-3}
        & \textbf{Absorption}       & \textbf{Blocking}       \\ \cline{2-3} 
\multicolumn{1}{c|}{\rotatebox{90}{\rlap{\textbf{Communication Density}}}} & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.32]{tests/interactivity/wssq/ca/pg_0002.pdf}} & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.32]{tests/interactivity/wssq/cb/pg_0002.pdf}} \\ \cline{2-3} 
\multicolumn{1}{c|}{\rotatebox{90}{\rlap{\textbf{Process Queue Length}}}}   & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.32]{tests/interactivity/wssq/ca/pg_0003.pdf}} & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.32]{tests/interactivity/wssq/cb/pg_0003.pdf}} \\ \cline{2-3} 
\end{tabular}
\caption{Comparison of two runs of $Interactivity_{(16,8)}$ on $MTRRWS$-$SQ$ using either Absorption or Blocking swap channels.}
    \label{tab:interactivity16-8-sq}
\end{table}

Note the effects of blocking on the apparent communication density of the 
application. Instead of visualizing only the completion of a swap, this chart
shows any attempted communication, even if it results in a block. Thus if a 
process is allowed to continuously check a required channel for a value, the 
density will increase, as it does for the Blocking channel chart. 

This difference is also apparent in the number of available processes each scheduler has
access to. The lengths of the process queues, fluctuate frequently in both
charts, however the absorption channel does so to quite a large degree. This
is to be expected since any communication which results in a block 
removes a process and any which results in a value returns an extra one.
Whereas the blocking channel chart, the queue size rapidly switches up and
down as it adds it's current process and gets the next one. We are also able 
to notice the tell-tail signs of the naive shared-queue work-stealing approach 
in the Blocking channel too (\ie~the single dominate process queue).

We discuss these channel differences further in the next section as we compare 
the cooperativity-conscious schedulers. At this point the operation of the 
blocking scheduler seems unmotivated, however, its effects on the 
Bipartite-Graph Aided Shuffling scheduler support the additional study.


\section{Cooperativity Mechanics}\label{sec:results-evaluation-feedback}

We now turn to the discussion of cooperativity-conscious scheduling.
Using our classical scheduler results as a base line we can evaluate 
the feedback schedulers independently. This will give an indication of what
may warrant further investigation, and testing. We direct the readers attention
to appendix~\ref{app:testcases} for full source descriptions of the test 
primitives used throughout this discussion. For any non-explicitly defined
parameter selections, the appendix will have their default values.

\subsection{Longevity-Based Batching}\label{sec:results-longbatcher}

The Longevity-Based Batcher was an experiment of worst-case scenarios. We
mention in section~\ref{sec:longevity based batching}, that a worst case 
scenario would be one where all processes were seen as long running and 
thus incapable of being batched. Our desire was for it to drop down into 
a common work-stealing mechanism, and should be the case despite the 
channel implementation or time quantum.

We would also like to look at how it would react to a $PRing_N$ execution. This
would be an optimal case as it would batch all processes up to the point where
$N$ is larger than the batch cut-off. Effectively, the longevity batcher would
act like a single threaded scheduler and forgo having to communicate accross
processors. We would subsequently be able to verify this positive result given
a communication and reduction density chart. If a single LPU were completely
saturated while all others were kept in waiting mode, this would indicate the
batching process was a success.

We also would like to look at a number of other possible tests to see the
common cases and how a batching scheduler would handle such applications.
Namely, various $ClusterComm_N$ and $PTree_{(W,N)}$ executions would allow 
for testing of process-absorption based rebatching. We may expect logical
work-groups to form batches, and only show poorer results in instances where
the worker thread computes for longer than the time quantum. We would be able
to verify this functionality by observing the process queue size and the work
load of each LPU. 


\subsubsection{Boundary-Case Scenarios}\label{sec:results-longbatcher-worstcase}

We will first consider the case of $ChugMachine_N$ for several values of $N$ where 
$0 <  N < P + 2$ and $P$ is the max number of LPUs on the machine, which in our case 
is $8$ \footnote{All testing was performed using an Intel Core i7-2820QM.}.  We will 
compare it to the graphs of $MTRRWS$-$SQ$ to determine how close to naive
work-stealing our implementation achieves. We will then subsequently consider
the case of $PRing_N$ for various values of $N$ surrounding the batch size, $B$,
to verify the absorption and batching assumptions.

\begin{table}[h!]
    \centering
    \begin{tabular}{ccccc}
        \multicolumn{5}{c}{$PRing_N$} \\ \cline{2-5}
        & \multicolumn{2}{c}{$MTRRWS$-$SQ$}  & \multicolumn{2}{c}{Long. Batcher}    \\ \cline{2-5}
    \multicolumn{1}{c|}{~} & \multicolumn{1}{c|}{Queue Length} & \multicolumn{1}{c|}{Reduc. Density} & 
        \multicolumn{1}{c|}{Queue Length} & \multicolumn{1}{c|}{Reduc. Density} \\ \cline{2-5}
        \multicolumn{1}{c|}{ \rotatebox{90}{\rlap{$N=P=8$}~} } & 
    \multicolumn{1}{c}{\includegraphics[scale=0.15]{tests/chugmachine/wssq/8/pg_0003.pdf}} &
        \multicolumn{1}{c|}{\includegraphics[scale=0.15]{tests/chugmachine/wssq/8/pg_0004.pdf}} & 
    \multicolumn{1}{c}{\includegraphics[scale=0.15]{tests/chugmachine/longbatcher/8/pg_0003.pdf}}&
        \multicolumn{1}{c|}{\includegraphics[scale=0.15]{tests/chugmachine/longbatcher/8/pg_0004.pdf}} \\ \cline{2-5}

        \multicolumn{1}{c|}{ \rotatebox{90}{\rlap{$N=2P=16$}~} } & 
    \multicolumn{1}{c}{\includegraphics[scale=0.15]{tests/chugmachine/wssq/16/pg_0003.pdf}} &
        \multicolumn{1}{c|}{\includegraphics[scale=0.15]{tests/chugmachine/wssq/16/pg_0004.pdf}} & 
    \multicolumn{1}{c}{\includegraphics[scale=0.15]{tests/chugmachine/longbatcher/16/pg_0003.pdf}}&
        \multicolumn{1}{c|}{\includegraphics[scale=0.15]{tests/chugmachine/longbatcher/16/pg_0004.pdf}} \\ \cline{2-5}
 
        \multicolumn{1}{c|}{ \rotatebox{90}{\rlap{$N=4P=32$}~} } & 
    \multicolumn{1}{c}{\includegraphics[scale=0.15]{tests/chugmachine/wssq/32/pg_0003.pdf}} &
        \multicolumn{1}{c|}{\includegraphics[scale=0.15]{tests/chugmachine/wssq/32/pg_0004.pdf}} & 
    \multicolumn{1}{c}{\includegraphics[scale=0.15]{tests/chugmachine/longbatcher/32/pg_0003.pdf}}&
        \multicolumn{1}{c|}{\includegraphics[scale=0.15]{tests/chugmachine/longbatcher/32/pg_0004.pdf}} \\ \cline{2-5}
 
\end{tabular}
\caption{Comparison of $ChugMachine_N$ spread on the Longevity-Batching Scheduler and $MTRRWS$-$SQ$.}
    \label{tab:chugmachine-longbatcher-testing}
\end{table}

First, table~\ref{tab:chugmachine-longbatcher-testing} visualizes a
$ChugMachine_N$ comparison with the Longevity-Based Batcher and $MTRRWS$-$SQ$. 
With the Longevity-Batcher, we can observe the common work-stealing behaviour 
with a primary LPU and minimal queue lengths on all others. It initially spreads
work out as the primary queue continues to chug. However, the $MTRRWS$-$SQ$ seem
to have an easier time of stealing the primary process which is in the process of
spawning the worker threads. Therefore the spread seems to be consistently more
even.

We hypothesized that the mechanism we were using for spawning into a batch was 
somehow making it improbable that it would be migrated to another core. In fact 
there are two mechanisms we have implemented for Long. Batcher to handle a spawn.
\begin{itemize}
    \item In `singleton' batching mode, if a spawn would cause the current batch 
    to be $\geq B$ then a new batch is created for the child and set as the 
    current batch. The old batch with the parent is placed on the queue.

    \item In `push-back' batching mode, if a spawn forces a new batch to be made, 
    we push the current batch onto the queue and keep the current process in the 
    same batch with as the new child. This will keep the parent close to it's 
    immediate child and also allow it to be quickly re-tested for more new spawns.
\end{itemize}
Note that in `push-back' mode, the scheduler with the primary process will never
be in a position to give it up until all children are finished being spawned. This
was our default for the Longevity Batcher in the test. As such, 
table~\ref{tab:chugmachine-longbatcher-singleton-testing} shows a re-execution of 
$PRing_{32}$ with `singleton'-mode turned on.

\begin{table}[ht!]
    \centering
    \begin{tabular}{ccc}
        & \multicolumn{2}{c}{$PRing_N$} \\ \cline{2-3}
        \multicolumn{1}{c|}{~} & \multicolumn{1}{c|}{Queue Length} & \multicolumn{1}{c|}{Reduc. Density} \\ \cline{2-3}
\multicolumn{1}{c|}{\rotatebox{90}{\rlap{$N=P=8$}~} } & 
    \multicolumn{1}{c}{\includegraphics[scale=0.20]{tests/chugmachine/longbatcher/32_singleton/pg_0003.pdf}}&
    \multicolumn{1}{c|}{\includegraphics[scale=0.20]{tests/chugmachine/longbatcher/32_singleton/pg_0004.pdf}} \\ \cline{2-3}
\end{tabular}
\caption{Re-run of $ChugMachine_N$ with Longevity-Batching Scheduler in `singlton' batching mode.}
    \label{tab:chugmachine-longbatcher-singleton-testing}
\end{table}

Despite giving it every oportunity to increase the spread, the catch of the parent
process being a short-running process (as it would spawn a new process before it would
hit it's time quantum) is just too great. There is a higher chance for it to get stolen,
but it will have a higher chance of staying batched until it reaches the point of waiting
for completion. This obviously limits our chances at immediate parallelism, thus the 
conclusion that Longevity-Based Batching is $MTRRWS$-$WS$ in the worst-case scenario 
is not quite true.

\begin{table}[ht!]
    \begin{tabular}{@{}cccc}
        & \multicolumn{3}{c}{$PRing_N$} \\ \cline{2-4}
    & $N=P=8$ & $N=B=10$ & $N=2*B=20$     \\ \cline{2-4} 
        \multicolumn{1}{c|}{\rotatebox{90}{\rlap{\textbf{Reduction Density}}}} & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.20]{tests/pring/longbatcher/8/pg_0004.pdf}} & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.20]{tests/pring/longbatcher/10/pg_0004.pdf}} & 
    \multicolumn{1}{c|}{\includegraphics[scale=0.20]{tests/pring/longbatcher/20/pg_0004.pdf}} \\ \cline{2-4} 
\end{tabular}
\caption{Comparison of different sized $PRing_N$ on a the Longevity Batching Scheduler with batch size $B=10$.}
    \label{tab:pring-longbatcher-testing}
\end{table}

Finally, table ~\ref{tab:pring-longbatcher-testing} visualizes the reduction 
densities of several $PRing_N$ executions using the Longevity-Based Batcher 
with Absorption Channels turned on. We note the obvious agreement with our 
assumption that the $PRing_N$ would get absorbed into a single batch and thus
contained to a single core. The spill-over at the beginning of the $PRing_{20}$
execution was due to the spawning of more than $B$ processes. However, after
their absorption due to communication, the Longevity-Based Batcher was free to
absorb all processes into the same batch.

\subsubsection{Average-Case Scenarios}\label{sec:results-longbatcher-avgcase}







\subsection{Channel Pinning}\label{sec:results-channelpinner}
\subsection{Bipartite-Graph Aided Shuffling}\label{sec:results-smartsort}

\section{A Comment on Swap Channels}\label{sec:results-swap-channels}

Swap channels provided a number of benefits on the side of the language 
designer. They reduce the complexity of channel implementation, and as shown, 
they lend themselves to a number of possible designs. We demonstrated just two 
possible implementations, the Blocking and Absorption channels. As such, the 
concept of a swap channel as a language primitive is extremely attractive. 
However, swapping poses some problems for realistic applications which we would
now like to discuss.

\begin{figure}
\centering
\inputminted[frame=lines,fontsize=\footnotesize]{csharp}{code/badclustercomm.els}
\caption{A naive but ineffectual $ClusterComm_{(N,M)}$ implementation.} 
\label{fig:bad-clustercomm}
\end{figure}

First, a swap channel does not lend itself to a level of fairness that would be
expected by a programmer. We lead with our implementation of 
$ClusterComm_{(N,M)}$ as example, which due to being on top of swap channels, 
was made to be much more enigmatic. Figure~\ref{fig:bad-clustercomm} gives an
example implementation of $ClusterComm_{(N,M)}$. Note the third parameter to
the application, which denotes the number of time's each of the $N$ processes
should communicate. The system therefore blocks until all processes synchronize
$X$ times before quiting.

Due to this, we must pose several restrictions on the possible values of $N$ and
$M$. Namely, $N$ must be an even number, since all processes would need to have a 
partner to swap with, and $M$ must be no greater than $\lfloor N/2 \rfloor$, any
more and it would be possible for a process to hang indefinitely.

However, these two restrictions are not enough to guarantee the process terminates.
In fact, most runs of this application, with any value of $N > 2$ would most 
likely hang forever. This is due to the bias our program creates when spawning
processes, as well as the type of fairness the swap channel semantics provides.

First, our bias we introduce is merely because we cannot batch spawn a set of
processes at the same time. As such we will spawn one process at a time which
may get a chance to run before all others. As such the first several processes
may reach their synchronization limit before we are even done spawning the rest
of the processes. Due to this, we may have a case where all but $M$ processes
have completed, and thus all channels are blocked indefinitely.

Secondly, the channel semantics have no inherent preference for unseen 
or new processes. The scheduler may easily get in a loop of running the same
subset of processes repeatedly, this would have the same effect as the above
even if we were able to solve the bias problem. As such, this is inherently an
issue with the capabilities of swap channels. 

Thus, the best we can do for $ClusterComm_{(N,M)}$, is to run until at least 
$N-M$ processes have met their quota. Note this approach is only acceptable 
under Symmetric message passing constructs. In asymmetrical, even if there was
a guarantee of an equal number of senders and receivers, all senders could be
blocked on one channel while all receivers could be blocked on another. 

But this issue points to another problem with swap channels, insofar as they do
not lend themselves to being primitives at all. Due to this fairness issue, a 
language with swap channels would be unable to build the asymmetrical constructs
most user's would like. As such, they have been useful merely for simulation 
purposes.

However, for further simulation of cooperativity, it may be adventagous to also 
consider the directionality of communication. The recognition of consumer and 
producer processes may lend itself to further gains as the recognition of 
communication and computation bound processes did. This is not to say all gains
in utilizing pure synchronization have been obtained. 
